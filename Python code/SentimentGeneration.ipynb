{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85d8f23e-b82b-45ea-93a5-86122ec4f595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.manifold import TSNE\n",
    "# import seaborn as sns\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a030a95-8c6c-4b03-9766-05d55dd3dcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01ce947b-7105-42e0-8b75-d342a5d3bdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c811ffe-13cd-4ead-a0d9-677d92089949",
   "metadata": {},
   "source": [
    "# Loading Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "235192fa-7d28-4014-9418-047d594ba924",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModel(torch.nn.Module):\n",
    "    def __init__(self, h1, h2, output_dim):\n",
    "        super(ClassifierModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(768, h1)\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "\n",
    "        self.linear2 = torch.nn.Linear(h1, h2)\n",
    "        self.dropout2 = torch.nn.Dropout(0.5)\n",
    "        self.activation2 = torch.nn.ReLU()\n",
    "\n",
    "        self.linear3 = torch.nn.Linear(h2, output_dim)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.linear1.weight)\n",
    "        torch.nn.init.zeros_(self.linear1.bias)\n",
    "        torch.nn.init.xavier_uniform_(self.linear2.weight)\n",
    "        torch.nn.init.zeros_(self.linear2.bias)\n",
    "        torch.nn.init.xavier_uniform_(self.linear3.weight)\n",
    "        torch.nn.init.zeros_(self.linear3.bias)\n",
    "  \n",
    "\n",
    "    def forward(self, embedding_batch):\n",
    "        #embedding_batch: [batch_size, embedding_length]\n",
    "        l1_out = self.linear1(embedding_batch)\n",
    "        l1_act = self.activation1(l1_out)\n",
    "\n",
    "        l2_out = self.linear2(l1_act)\n",
    "        l2_drop = self.dropout2(l2_out)\n",
    "        l2_act = self.activation2(l2_drop)\n",
    "\n",
    "        out = self.sigmoid(self.linear3(l2_act))\n",
    "        return out\n",
    "  \n",
    "\n",
    "    def reset(self):\n",
    "        torch.nn.init.xavier_uniform_(self.linear1.weight)\n",
    "        torch.nn.init.zeros_(self.linear1.bias)\n",
    "        torch.nn.init.xavier_uniform_(self.linear2.weight)\n",
    "        torch.nn.init.zeros_(self.linear2.bias)\n",
    "        torch.nn.init.xavier_uniform_(self.linear3.weight)\n",
    "        torch.nn.init.zeros_(self.linear3.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48281e5e-8544-4b2d-8956-996b1ac9ba3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierModel(\n",
       "  (linear1): Linear(in_features=768, out_features=250, bias=True)\n",
       "  (activation1): ReLU()\n",
       "  (linear2): Linear(in_features=250, out_features=250, bias=True)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (activation2): ReLU()\n",
       "  (linear3): Linear(in_features=250, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = torch.load('model_checkpoints/model.pt')\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a12a4d8-47d9-4117-a6ac-a1f29f9f4445",
   "metadata": {},
   "source": [
    "# Reading New Stock Data and Computing Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8795024d-eb43-468b-8695-30056070c32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>message</th>\n",
       "      <th>datetime</th>\n",
       "      <th>user</th>\n",
       "      <th>message_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>peak profit last 6 expired option alerts aapl ...</td>\n",
       "      <td>2020-07-19 09:49:35</td>\n",
       "      <td>1442893</td>\n",
       "      <td>229008387</td>\n",
       "      <td>2020-07-19</td>\n",
       "      <td>09:49:35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>aapl jul 17 382 50 calls option volume 144 44 ...</td>\n",
       "      <td>2020-07-19 09:47:26</td>\n",
       "      <td>1442893</td>\n",
       "      <td>229008357</td>\n",
       "      <td>2020-07-19</td>\n",
       "      <td>09:47:26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>tsla market true bubble territory profitable c...</td>\n",
       "      <td>2020-07-19 09:01:25</td>\n",
       "      <td>1115913</td>\n",
       "      <td>229007569</td>\n",
       "      <td>2020-07-19</td>\n",
       "      <td>09:01:25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>aapl analyzed 26 analysts buy consensus 86 ana...</td>\n",
       "      <td>2020-07-19 08:13:00</td>\n",
       "      <td>47688</td>\n",
       "      <td>229006733</td>\n",
       "      <td>2020-07-19</td>\n",
       "      <td>08:13:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>aapl new article dogs dow august 4 adopt ignore</td>\n",
       "      <td>2020-07-19 07:54:05</td>\n",
       "      <td>1555408</td>\n",
       "      <td>229006403</td>\n",
       "      <td>2020-07-19</td>\n",
       "      <td>07:54:05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol                                            message  \\\n",
       "0   AAPL  peak profit last 6 expired option alerts aapl ...   \n",
       "1   AAPL  aapl jul 17 382 50 calls option volume 144 44 ...   \n",
       "2   AAPL  tsla market true bubble territory profitable c...   \n",
       "3   AAPL  aapl analyzed 26 analysts buy consensus 86 ana...   \n",
       "4   AAPL    aapl new article dogs dow august 4 adopt ignore   \n",
       "\n",
       "              datetime     user  message_id        Date      Time  label  \n",
       "0  2020-07-19 09:49:35  1442893   229008387  2020-07-19  09:49:35      1  \n",
       "1  2020-07-19 09:47:26  1442893   229008357  2020-07-19  09:47:26      1  \n",
       "2  2020-07-19 09:01:25  1115913   229007569  2020-07-19  09:01:25      1  \n",
       "3  2020-07-19 08:13:00    47688   229006733  2020-07-19  08:13:00      1  \n",
       "4  2020-07-19 07:54:05  1555408   229006403  2020-07-19  07:54:05      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Combined_percentage_same.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d512f065-d7f8-4013-850a-2506c695e37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6450989, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc3771e2-a9d7-4516-8574-65b95eeeb11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9546c713-ba0f-467f-8f52-007dedeb3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embeddings(sentences: list):\n",
    "    # print(sentences)\n",
    "    # Tokenize sentences\n",
    "    # print(\"tokenizing\")\n",
    "    try:\n",
    "        encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt').to('cuda')\n",
    "    except Exception:\n",
    "        print(sentences)\n",
    "        print(type(sentences))\n",
    "        return None\n",
    "    # print(\"done\")\n",
    "\n",
    "    # print(\"running through bert\")\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    # print(\"done\")\n",
    "    return model_output[0][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b8091e2-71bf-4055-b058-5882c6f17305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Sentiments_and_Save(df, batch_size=4, filename='All_Embs.csv'):\n",
    "    data_len = df.shape[0]\n",
    "\n",
    "    sentences_df = np.array(df['message'])\n",
    "    embeddings = []\n",
    "    print(f'Getting BERT embeddings for {data_len} samples')\n",
    "\n",
    "    print('Progress: ', end='')\n",
    "    thresh = 1\n",
    "    iters = math.ceil(data_len/batch_size)\n",
    "    for i in range(iters):\n",
    "        start = i*batch_size\n",
    "        end = min(data_len, start + batch_size)\n",
    "        sentences = list(sentences_df[start:end])\n",
    "        embeddings.append(get_sentence_embeddings(sentences))\n",
    "        if i*100.0/iters > thresh:\n",
    "            print('|', end='')\n",
    "            thresh += 1\n",
    "    print('\\nDone')\n",
    "\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    with torch.no_grad():\n",
    "        sentiments = net(embeddings)\n",
    "    # embeddings_np = embeddings.cpu().detach().numpy()\n",
    "    \n",
    "    del embeddings\n",
    "    # print(embeddings_np.shape)\n",
    "    sentiments_np = sentiments.cpu().detach().numpy()\n",
    "\n",
    "    ret_df = pd.DataFrame()\n",
    "    ret_df['Date'] = np.array(df['Date']).reshape(-1,)\n",
    "    ret_df['Symbol'] = np.array(df['symbol']).reshape(-1,)\n",
    "    ret_df['Sentiment'] = sentiments_np.reshape(-1,)\n",
    "    ret_df.to_csv(filename)\n",
    "\n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee05ab82-8787-46f1-9a99-8b0f7f43105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT embeddings for 64490 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64490, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64491 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64491, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 63291 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(63291, 3)\n",
      "Getting BERT embeddings for 64391 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64391, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64492 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64492, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64492 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64492, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64492 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64492, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64492 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64492, 3)\n",
      "Getting BERT embeddings for 64492 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64492, 3)\n",
      "Getting BERT embeddings for 64492 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64492, 3)\n",
      "Getting BERT embeddings for 64493 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64493, 3)\n",
      "Getting BERT embeddings for 64465 samples\n",
      "Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "Done\n",
      "(64465, 3)\n"
     ]
    }
   ],
   "source": [
    "data_len = df.shape[0]\n",
    "base_file_name = 'NewStock/NewStock_Sentiment_Batch_'\n",
    "batch_size = math.ceil(data_len / 100)\n",
    "for i in range(50, 100):\n",
    "    batch_start = i*batch_size\n",
    "    batch_end = min(data_len, batch_start + batch_size)\n",
    "    ret_df = Get_Sentiments_and_Save(df.loc[batch_start:batch_end,:],\n",
    "                                    batch_size=2,\n",
    "                                    filename=base_file_name+f'{i:03d}.csv')\n",
    "    print(ret_df.shape)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b15bc5cd-3401-4327-ab25-73a23cdb22a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10750, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b8c8d5-0add-4f6e-aa62-8681c63670af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
